---
title: "GR5243 Project 1"
output: html_notebook
---

As the new president Donald Trump's just gave his new inaugural speech, in this project, we are going to looking at all inaugural speeches given by presidents. 

Before we are doing any further analysis, we load relative packages and our text file into R.

```{r, message=FALSE, warning=FALSE}
packages.used=c("rvest", "tibble", "qdap", 
                "sentimentr", "gplots", "dplyr",
                "tm", "syuzhet", "factoextra", 
                "beeswarm", "scales", "RColorBrewer",
                "RANN", "tm", "topicmodels")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}

# load packages
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")

source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
```


```{r, message=FALSE, warning=FALSE}
### Inauguaral speeches
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
# Get link URLs
# f.speechlinks is a function for extracting links from the list of speeches. 
inaug=f.speechlinks(main.page)
#head(inaug)
as.Date(inaug[,1], format="%B %e, %Y")
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.

#### Nomination speeches
main.page=read_html("http://www.presidency.ucsb.edu/nomination.php")
# Get link URLs
nomin <- f.speechlinks(main.page)
#head(nomin)
#
#### Farewell speeches
main.page=read_html("http://www.presidency.ucsb.edu/farewell_addresses.php")
# Get link URLs
farewell <- f.speechlinks(main.page)

inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
```

```{r}
#Load the speeches:
folder<-file.path("~", "Desktop", "InauguralSpeeches")
#speeches<-list.files(path = folder, pattern = "*.txt")
text<-Corpus(DirSource(folder))

```

As we all know, Republican and Democratic are the two biggest parties in the America. So our focus is going to be at these parties. Before jump into the conclusion stated directly, we can use some graph and numerical tool to confirm this statement.  

```{r}
library(ggplot2)
speech.list$Party<-as.factor(speech.list$Party)
speech.list$Win<-as.factor(speech.list$Win)
levels(speech.list$Win)[1]<-"No"
levels(speech.list$Win)[2]<-"Yes"
ggplot(aes(x=Win,fill=Party),data=speech.list)+geom_bar(position="fill")+scale_fill_brewer(palette="Set1")+xlab("Winning Presidency")+ylab("Percent")+coord_flip()+theme_bw()+ggtitle("Figure1: Propotion of Winning Presidency")+theme(plot.title=element_text(lineheight=.8))
table(as.factor(inaug.list$Party))/length(inaug.list$Party)
```

From this Mosaic plot, we can see those presidents who won presidency, most of them are from Republican Party. This idea is also supported by the table summary above. So from now on, our analysis can only be about Republican and Democratic. 

2. Do Repbulican and Democratic focus on different aspects?

```{r}
library(tm)
library(RColorBrewer)
library(wordcloud)
library(dplyr)
library(tidytext)

text<-tm_map(text, removeWords, stopwords("english"))
text <- tm_map(text, stripWhitespace)
text <- tm_map(text, content_transformer(tolower))
text <- tm_map(text, removeWords, character(0))
text <- tm_map(text, removeWords, stopwords("english"))
text<-tm_map(text, removePunctuation)
text <- tm_map(text, PlainTextDocument) 

#Check the overall wordcloud first:
wordcloud(text,random.order=F,scale=c(3,0.5),max.word=40,colors=rainbow(40))
```
One thing we can use the overall wordcloud for is to continue removing unuseful words in the speeches. Based on the wordcloud above, we probably should eliminate words like will,people, government,shall, may, must, made, world,etc. We can repeat this steps many times and choose the most useful set of words to you. 

```{r}
#remove unuseful words mentioned above
text<-tm_map(text, removeWords, c("will","people", "government","shall", "may", "must","made", "world","can","every","country","now","good","upon","states","nation","nations","america","great","national","rights","one","let","new"))
wordcloud(text,random.order=F,scale=c(3,0.5),max.word=20,colors=rainbow(40))
```
From the above wordcloud image, most of the words actually make sense.So we can start the comparison for Republican party and Democratic party from here.

```{r}
#Extract speeches for Democratic
demo<-text[which(inaug.list$Party=="Democratic")]

#Extract speeches for Republican 
repub<-text[which(inaug.list$Party=="Republican")]

#Check out the wordcloud of most frequent words for Democratic
wordcloud(demo,random.order=F,scale=c(3,0.5),max.word=40,colors=rainbow(40))
wordcloud(repub,random.order=F,scale=c(3,0.5),max.word=40,colors=rainbow(40))
```

Looking at the those two wordcloud above, we can see the Republicans tends to 



```{r}
tdm.tidy<-tidy(tdm)
tdm.overall<-summarise(group_by(tdm.tidy, term), sum(count))

wordcloud(tdm.overall$term, tdm.overall$`sum(count)`,
          scale=c(15,0.5),
          max.words=20,
          min.freq=1,
          random.order=FALSE,
          rot.per=0.3,
          use.r.layout=T,
          random.color=FALSE,
          colors=brewer.pal(9,"Blues"))
```


```{r}
tdm<-TermDocumentMatrix(text)
freq <- colSums(as.matrix(tdm)) 
freq<-sort(freq,decreasing=F)
freq

dtms <- removeSparseTerms(textm, 0.1) # This makes a matrix that is 10% empty space, maximum.   

```


