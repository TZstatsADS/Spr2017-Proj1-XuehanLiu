{
    "collab_server" : "",
    "contents" : "---\ntitle: 'Tutorial (week 2) A: Interactive R Notebook'\nruntime: shiny\noutput:\n  html_document: default\n  html_notebook: default\n---\n\nThis is an *Interactive* [R Markdown](http://rmarkdown.rstudio.com) Notebook. It generates an HTML notebook that would allow users to interactively explore your analysis results. \n\nWe will use the presidential inaugural speech word clouds as examples. \n\n#Step 0 - Install and load libraries\n```{r, message=FALSE, warning=FALSE}\npackages.used=c(\"tm\", \"wordcloud\", \"RColorBrewer\", \n                \"dplyr\", \"tydytext\")\n\n# check packages that need to be installed.\npackages.needed=setdiff(packages.used, \n                        intersect(installed.packages()[,1], \n                                  packages.used))\n# install additional packages\nif(length(packages.needed)>0){\n  install.packages(packages.needed, dependencies = TRUE,\n                   repos='http://cran.us.r-project.org')\n}\n\nlibrary(tm)\nlibrary(wordcloud)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nlibrary(tydytext)\n```\n\nThis notebook was prepared with the following environmental settings.\n\n```{r}\nprint(R.version)\n```\n\n# Step 1 - Read in the speeches\n```{r}\nfolder.path=\"../data/inaugurals/\"\nspeeches=list.files(path = folder.path, pattern = \"*.txt\")\nprex.out=substr(speeches, 6, nchar(speeches)-4)\n\nff.all<-Corpus(DirSource(folder.path))\n```\n\n#Step 2 - Text processing\n\nSee [Basic Text Mining in R](https://rstudio-pubs-static.s3.amazonaws.com/31867_8236987cf0a8444e962ccd2aec46d9c3.html) for a more comprehensive discussion. \n\nFor the speeches, we remove extra white space, convert all letters to the lower case, remove [stop words](https://github.com/arc12/Text-Mining-Weak-Signals/wiki/Standard-set-of-english-stopwords), removed empty words due to formatting errors, and remove punctuation. Then we compute the [Document-Term Matrix (DTM)](https://en.wikipedia.org/wiki/Document-term_matrix). \n\n```{r}\nff.all<-tm_map(ff.all, stripWhitespace)\nff.all<-tm_map(ff.all, content_transformer(tolower))\nff.all<-tm_map(ff.all, removeWords, stopwords(\"english\"))\nff.all<-tm_map(ff.all, removeWords, character(0))\nff.all<-tm_map(ff.all, removePunctuation)\n\ntdm.all<-TermDocumentMatrix(ff.all)\n\ntdm.tidy=tidy(tdm.all)\n\ntdm.overall=summarise(group_by(tdm.tidy, term), sum(count))\n```\n\n#Step 3 - Inspect an overall wordcloud\n```{r, fig.height=6, fig.width=6}\nwordcloud(tdm.overall$term, tdm.overall$`sum(count)`,\n          scale=c(5,0.5),\n          max.words=100,\n          min.freq=1,\n          random.order=FALSE,\n          rot.per=0.3,\n          use.r.layout=T,\n          random.color=FALSE,\n          colors=brewer.pal(9,\"Blues\"))\n```\n\n#Step 4 - compute TF-IDF weighted document-term matrices for individual speeches. \nAs we would like to identify interesting words for each inaugural speech, we use [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to weigh each term within each speech. It highlights terms that are more specific for a particular speech. \n\n```{r}\ndtm <- DocumentTermMatrix(ff.all,\n                          control = list(weighting = function(x)\n                                             weightTfIdf(x, \n                                                         normalize =FALSE),\n                                         stopwords = TRUE))\nff.dtm=tidy(dtm)\n```\n\n#Step 5- Interactive visualize important words in individual speeches\n```{r, warning=FALSE}\nlibrary(shiny)\n\nshinyApp(\n    ui = fluidPage(\n      fluidRow(style = \"padding-bottom: 20px;\",\n        column(4, selectInput('speech1', 'Speech 1',\n                              speeches,\n                              selected=speeches[5])),\n        column(4, selectInput('speech2', 'Speech 2', speeches,\n                              selected=speeches[9])),\n        column(4, sliderInput('nwords', 'Number of words', 3,\n                               min = 20, max = 200, value=100, step = 20))\n      ),\n      fluidRow(\n        plotOutput('wordclouds', height = \"400px\")\n      )\n    ),\n\n    server = function(input, output, session) {\n\n      # Combine the selected variables into a new data frame\n      selectedData <- reactive({\n        list(dtm.term1=ff.dtm$term[ff.dtm$document==as.character(input$speech1)],\n             dtm.count1=ff.dtm$count[ff.dtm$document==as.character(input$speech1)],\n             dtm.term2=ff.dtm$term[ff.dtm$document==as.character(input$speech2)],\n             dtm.count2=ff.dtm$count[ff.dtm$document==as.character(input$speech2)])\n      })\n\n      output$wordclouds <- renderPlot(height = 400, {\n        par(mfrow=c(1,2), mar = c(0, 0, 3, 0))\n        wordcloud(selectedData()$dtm.term1, \n                  selectedData()$dtm.count1,\n              scale=c(4,0.5),\n              max.words=input$nwords,\n              min.freq=1,\n              random.order=FALSE,\n              rot.per=0,\n              use.r.layout=FALSE,\n              random.color=FALSE,\n              colors=brewer.pal(10,\"Blues\"), \n            main=input$speech1)\n        wordcloud(selectedData()$dtm.term2, \n                  selectedData()$dtm.count2,\n              scale=c(4,0.5),\n              max.words=input$nwords,\n              min.freq=1,\n              random.order=FALSE,\n              rot.per=0,\n              use.r.layout=FALSE,\n              random.color=FALSE,\n              colors=brewer.pal(10,\"Blues\"), \n            main=input$speech2)\n      })\n    },\n\n    options = list(height = 600)\n)\n```\n\n\n\n\n# Further readings\n\n+ [Text mining with `tidytext`](http://tidytextmining.com/).\n+ [Basic Text Mining in R](https://rstudio-pubs-static.s3.amazonaws.com/31867_8236987cf0a8444e962ccd2aec46d9c3.html)\n",
    "created" : 1485792656531.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3484350101",
    "id" : "A3715273",
    "lastKnownWriteTime" : 1485550107,
    "last_content_update" : 1485550107,
    "path" : "~/Desktop/5243 ADS/Tutorial2/doc/InteractiveWordCloud.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}